# An Introduction to Machine Learning in Toxicology

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## An introduction to Artificial Intelligence

### Definition

### Why AI is now

### Open Source Foundation models

## Types of AI

## AI in Toxicology

## A hands-on example

All practical machine learning investigations basically have the same build-up. It is imparative that we need data as imput to train a machine learning model. Sometimes, we can use an existing foundation model that has already been trained on a large volume of data. For example models on [Hugging Face](https://huggingface.co). If no pre-existing model is available, or if the model is not tuned to the specific taks, we need to build a model ourselves.

In this exercise we will go through a number of typical steps to arrive a prediction model:

 1. Get data
 2. Inspect raw dataset (exploratory data analysis)
 3. Clean data
 4. Select (a number of) suitable machine learning algorithms
 5. Preprocess data to suit machine learning modelling
 6. Split data into a training and test datasets
 7. Define tuning parameters and a grid to tune them
 8. Prototype a single model - train -> tune -> train -> test -> evaluate
 9. Assemble a collection of algorithms in a workflow
 10. Fit all models - train -> tune -> train -> test -> evaluate
 11. Define best model
 12. Put model in production to predict new data
 
**I cannot empahsize enough to spend a lot of time on steps 1-3. Literally, take a look at the data and try to do the exploration as thorough as possible. If you ask me, in science the step of exploratory data anlaysis is heavy under-appreciated. Normally, scientist have a tendency to dive straight into the modelling or statistics. This is simply a bad reflex. When you do not know and understand your data in much detail, problems will arise in a later stage.**

Also, do everything using a programming language such as R or Python. It will take some time to learn how to use them, but you will gain a world of possibilities. Furthermore, and more imoportant: it will make everything you do reproducible.

Some good resources to start learning about R in the context of data science and reproducible research

 - [R4DS](https://r4ds.hadley.nz/)
 - [A Beginner's Guide to Conducting Reproducible Research](https://doi.org/10.1002/bes2.1801)
 - [Reproducible Research: A Retrospective](https://doi.org/10.1146/annurev-publhealth-012420-105110)
 - [Guerilla Analytics](https://guerrilla-analytics.net/)
 - [Reproducible Research with R and RStudio (Third Edition)](https://github.com/christophergandrud/Rep-Res-Book/tree/master/rep-res-3rd-edition)

For a compact reference to a training on implementing Reproducible Research see [this Bookdown project](https://github.com/VHP4Safety/RepRes_VHP_Shortintro).
 















